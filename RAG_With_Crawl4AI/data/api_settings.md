[ Skip to content ](https://ai.pydantic.dev/api/settings/<#pydantic_aisettings>)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/settings/<../..> "PydanticAI")
PydanticAI 
pydantic_ai.settings 
Initializing search 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/settings/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/api/settings/<../..> "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://ai.pydantic.dev/api/settings/<https:/github.com/pydantic/pydantic-ai> "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/api/settings/<../..>)
  * [ Installation  ](https://ai.pydantic.dev/api/settings/install/>)
  * [ Getting Help  ](https://ai.pydantic.dev/api/settings/help/>)
  * [ Contributing  ](https://ai.pydantic.dev/api/settings/contributing/>)
  * [ Troubleshooting  ](https://ai.pydantic.dev/api/settings/troubleshooting/>)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/api/settings/agents/>)
    * [ Models  ](https://ai.pydantic.dev/api/settings/models/>)
    * [ Dependencies  ](https://ai.pydantic.dev/api/settings/dependencies/>)
    * [ Function Tools  ](https://ai.pydantic.dev/api/settings/tools/>)
    * [ Results  ](https://ai.pydantic.dev/api/settings/results/>)
    * [ Messages and chat history  ](https://ai.pydantic.dev/api/settings/message-history/>)
    * [ Testing and Evals  ](https://ai.pydantic.dev/api/settings/testing-evals/>)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/api/settings/logfire/>)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/api/settings/multi-agent-applications/>)
  * [ Examples  ](https://ai.pydantic.dev/api/settings/examples/>)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/api/settings/examples/pydantic-model/>)
    * [ Weather agent  ](https://ai.pydantic.dev/api/settings/examples/weather-agent/>)
    * [ Bank support  ](https://ai.pydantic.dev/api/settings/examples/bank-support/>)
    * [ SQL Generation  ](https://ai.pydantic.dev/api/settings/examples/sql-gen/>)
    * [ Flight booking  ](https://ai.pydantic.dev/api/settings/examples/flight-booking/>)
    * [ RAG  ](https://ai.pydantic.dev/api/settings/examples/rag/>)
    * [ Stream markdown  ](https://ai.pydantic.dev/api/settings/examples/stream-markdown/>)
    * [ Stream whales  ](https://ai.pydantic.dev/api/settings/examples/stream-whales/>)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/api/settings/examples/chat-app/>)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/settings/<../agent/>)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/settings/<../tools/>)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/settings/<../result/>)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/settings/<../messages/>)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/settings/<../exceptions/>)
    * pydantic_ai.settings  [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/settings/<./>) Table of contents 
      * [ settings  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings>)
      * [ ModelSettings  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings>)
        * [ max_tokens  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.max_tokens>)
        * [ temperature  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.temperature>)
        * [ top_p  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.top_p>)
        * [ timeout  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.timeout>)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/settings/<../usage/>)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/settings/<../format_as_xml/>)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/settings/<../models/base/>)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/settings/<../models/openai/>)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/settings/<../models/anthropic/>)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/settings/<../models/gemini/>)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/settings/<../models/vertexai/>)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/settings/<../models/groq/>)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/settings/<../models/mistral/>)
    * [ pydantic_ai.models.ollama  ](https://ai.pydantic.dev/api/settings/<../models/ollama/>)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/settings/<../models/test/>)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/settings/<../models/function/>)


Table of contents 
  * [ settings  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings>)
  * [ ModelSettings  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings>)
    * [ max_tokens  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.max_tokens>)
    * [ temperature  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.temperature>)
    * [ top_p  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.top_p>)
    * [ timeout  ](https://ai.pydantic.dev/api/settings/<#pydantic_ai.settings.ModelSettings.timeout>)


  1. [ Introduction  ](https://ai.pydantic.dev/api/settings/<../..>)
  2. [ API Reference  ](https://ai.pydantic.dev/api/settings/<../agent/>)


# `pydantic_ai.settings`
###  ModelSettings
Bases: `TypedDict[](https://ai.pydantic.dev/api/settings/<https:/typing-extensions.readthedocs.io/en/latest/index.html#typing_extensions.TypedDict> "typing_extensions.TypedDict")`
Settings to configure an LLM.
Here we include only settings which apply to multiple models / model providers.
Source code in `pydantic_ai_slim/pydantic_ai/settings.py`
```
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
```
| ```
class ModelSettings(TypedDict, total=False):
"""Settings to configure an LLM.
  Here we include only settings which apply to multiple models / model providers.
  """
  max_tokens: int
"""The maximum number of tokens to generate before stopping.
  Supported by:
  * Gemini
  * Anthropic
  * OpenAI
  * Groq
  """
  temperature: float
"""Amount of randomness injected into the response.
  Use `temperature` closer to `0.0` for analytical / multiple choice, and closer to a model's
  maximum `temperature` for creative and generative tasks.
  Note that even with `temperature` of `0.0`, the results will not be fully deterministic.
  Supported by:
  * Gemini
  * Anthropic
  * OpenAI
  * Groq
  """
  top_p: float
"""An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.
  So 0.1 means only the tokens comprising the top 10% probability mass are considered.
  You should either alter `temperature` or `top_p`, but not both.
  Supported by:
  * Gemini
  * Anthropic
  * OpenAI
  * Groq
  """
  timeout: float | Timeout
"""Override the client-level default timeout for a request, in seconds.
  Supported by:
  * Gemini
  * Anthropic
  * OpenAI
  * Groq
  """

```
  
---|---  
####  max_tokens `instance-attribute`
```
max_tokens: int[](https://ai.pydantic.dev/api/settings/<https:/docs.python.org/3/library/functions.html#int>)

```

The maximum number of tokens to generate before stopping.
Supported by:
  * Gemini
  * Anthropic
  * OpenAI
  * Groq


####  temperature `instance-attribute`
```
temperature: float[](https://ai.pydantic.dev/api/settings/<https:/docs.python.org/3/library/functions.html#float>)

```

Amount of randomness injected into the response.
Use `temperature` closer to `0.0` for analytical / multiple choice, and closer to a model's maximum `temperature` for creative and generative tasks.
Note that even with `temperature` of `0.0`, the results will not be fully deterministic.
Supported by:
  * Gemini
  * Anthropic
  * OpenAI
  * Groq


####  top_p `instance-attribute`
```
top_p: float[](https://ai.pydantic.dev/api/settings/<https:/docs.python.org/3/library/functions.html#float>)

```

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.
So 0.1 means only the tokens comprising the top 10% probability mass are considered.
You should either alter `temperature` or `top_p`, but not both.
Supported by:
  * Gemini
  * Anthropic
  * OpenAI
  * Groq


####  timeout `instance-attribute`
```
timeout: float[](https://ai.pydantic.dev/api/settings/<https:/docs.python.org/3/library/functions.html#float>) | Timeout

```

Override the client-level default timeout for a request, in seconds.
Supported by:
  * Gemini
  * Anthropic
  * OpenAI
  * Groq


Â© Pydantic Services Inc. 2024 to present 
