{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- Self attention demo based on youtube video:\n",
        "  - https://www.youtube.com/watch?v=FepOyFtYQ6I\n",
        "  - added detailed notes and detailed end2end demo"
      ],
      "metadata": {
        "id": "bO_aoa7SsR7I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBi0Sk-OPubu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eIntOHGPubu"
      },
      "source": [
        "# Create Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdwlqV4TPubv",
        "outputId": "536bff5b-cbaa-4b97-a272-6e81597a160e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input text is: \"The narrator lightly suggested to like and subscribe\"\n",
            "The number of words in the input text is: 8\n",
            "\n",
            "The input text is tokenized and randomly embedded as such:\n",
            "Each Row is a word in the sentence\n",
            "Each word in this case has embedding dimension of 5\n",
            "The batch size represents the number of independent input sequences (or sentences) being processed simultaneously.\n",
            "\n",
            " tensor([[[-0.7257, -0.2526,  0.3268, -1.7870,  1.8246],\n",
            "         [-0.7592,  1.1202,  0.4328,  0.4880, -0.4778],\n",
            "         [ 1.8166,  1.2236, -0.6612, -0.4214, -0.4998],\n",
            "         [ 0.0030,  1.2262, -0.7511, -1.0392, -1.2740],\n",
            "         [ 2.5219,  0.8230, -0.0484,  0.7657,  1.9927],\n",
            "         [ 0.9559, -0.8261, -0.7600, -0.8562,  0.9490],\n",
            "         [ 0.3757, -0.6655, -0.7089, -1.1258, -1.7186],\n",
            "         [-1.4376,  0.7903,  1.1819, -0.6853, -0.1158]]])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 1\n",
        "context_length = 8  # number of words in sentence\n",
        "token_dimensions = 5    # number of tokens associated with each word in sentence\n",
        "input_text = \"The narrator lightly suggested to like and subscribe\"\n",
        "\n",
        "x = torch.randn(batch_size, context_length, token_dimensions)\n",
        "\n",
        "print(f\"The input text is: \\\"{input_text}\\\"\")\n",
        "print(f\"The number of words in the input text is: {len(input_text.split())}\\n\")\n",
        "print(f\"The input text is tokenized and randomly embedded as such:\\nEach Row is a word in the sentence\\nEach word in this case has embedding dimension of 5\")\n",
        "print(f\"The batch size represents the number of independent input sequences (or sentences) being processed simultaneously.\\n\\n {x}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoaYH50FTNC8",
        "outputId": "be9dff31-c9fb-4e41-e636-422579e21e13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OasNxo-CPubw"
      },
      "source": [
        "# Initialize Q/K/V Matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf0lz0y9Pubw",
        "outputId": "b179f5f3-a793-48ec-eb8b-e52c687c4a2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W_query: \n",
            "tensor([[-0.3549,  0.6888, -1.8475,  2.0551],\n",
            "        [ 0.7558,  1.8989,  0.1634, -0.7779],\n",
            "        [-0.3782,  1.9388,  0.3392, -0.6146],\n",
            "        [ 0.1113, -1.2743, -0.0768, -1.5890],\n",
            "        [ 1.2371, -0.0400, -0.7531, -0.1659]])\n",
            "W_key: \n",
            "tensor([[-1.1238,  1.5980,  0.3749,  0.3054],\n",
            "        [ 0.1530,  0.4081,  0.1188, -0.9981],\n",
            "        [ 0.9333, -0.5097, -0.2662, -0.5017],\n",
            "        [-0.2254, -1.2181, -0.2420, -1.4742],\n",
            "        [ 0.1965, -0.0663, -1.3431,  1.8577]])\n",
            "W_value: \n",
            "tensor([[-0.1726, -0.6899, -0.2131, -0.0090],\n",
            "        [-0.4398,  0.9675,  0.1771,  0.3217],\n",
            "        [ 0.0231,  0.3393,  0.2836, -0.7246],\n",
            "        [ 0.7213, -1.3536,  1.8759,  0.0221],\n",
            "        [ 1.1208, -1.1661, -0.3736, -1.2629]])\n"
          ]
        }
      ],
      "source": [
        "weight_dimensions = 4\n",
        "W_query = torch.randn(token_dimensions, weight_dimensions)\n",
        "W_key = torch.randn(token_dimensions, weight_dimensions)\n",
        "W_value = torch.randn(token_dimensions, weight_dimensions)\n",
        "print(f\"W_query: \\n{W_query}\")\n",
        "print(f\"W_key: \\n{W_key}\")\n",
        "print(f\"W_value: \\n{W_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the shapes\n",
        "print(f\"W_query shape: {W_query.shape}\")\n",
        "print(f\"W_key shape: {W_key.shape}\")\n",
        "print(f\"W_value shape: {W_value.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xGiWSYATVDK",
        "outputId": "bcc8a17a-f43c-45b7-f0ad-11dc0df06cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W_query shape: torch.Size([5, 4])\n",
            "W_key shape: torch.Size([5, 4])\n",
            "W_value shape: torch.Size([5, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBPGrwpBPubw"
      },
      "source": [
        "# 1. Compute Attention Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_wGuVjTPubw"
      },
      "outputs": [],
      "source": [
        "Q = x @ W_query # all the query vectors\n",
        "K = x @ W_key\n",
        "V = x @ W_value"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Note that we are multiplying a 8X5 matrix with 5X4 matrix\\nThis gives us a 8X4 matrix for each of Q/K/V\\nThis means that each word now has 4 weights for Q/K/V\\n\")\n",
        "print(f\"Q: \\n{Q}\\nShape:{Q.shape}\\n\")\n",
        "print(f\"K: \\n{K}\\nShape:{K.shape}\\n\")\n",
        "print(f\"V: \\n{V}\\nShape:{V.shape}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCuPJw9-SeXc",
        "outputId": "20052529-8956-42c0-ab2c-aa2cebddb03e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note that we are multiplying a 8X5 matrix with 5X4 matrix\n",
            "This gives us a 8X4 matrix for each of Q/K/V\n",
            "This means that each word now has 4 weights for Q/K/V\n",
            "\n",
            "Q: \n",
            "tensor([[[-1.9967,  2.1752,  0.8728,  1.0870],\n",
            "         [-3.0137, -1.5486,  0.2039, -0.2588],\n",
            "         [ 2.9773,  0.0719,  0.4075,  0.6502],\n",
            "         [ 0.8649,  0.6996, -0.9332, -1.0033],\n",
            "         [ 0.0197, -2.8402, -0.4329, -0.3401],\n",
            "         [ 3.1839, -2.0164, -2.6627, -2.3368],\n",
            "         [ 3.7926,  2.1223, -0.7384,  0.0586],\n",
            "         [ 2.3284,  2.5654, -1.8933, -1.8567]]])\n",
            "Shape:torch.Size([1, 8, 4])\n",
            "\n",
            "K: \n",
            "tensor([[[-0.6510, -3.4445, -5.8930, -2.4487],\n",
            "         [-0.9062,  0.3995,  0.2874,  0.4378],\n",
            "         [ 0.7957, -0.8254,  1.6934,  0.6866],\n",
            "         [-0.0456,  0.0406,  0.9108,  0.8759],\n",
            "         [ 1.2129,  1.6016, -1.6721, -1.1057],\n",
            "         [ 2.1940,  8.2014,  3.8594,  0.1499],\n",
            "         [ 1.6181,  0.7473, -2.0546, -1.7937],\n",
            "         [-0.0881,  2.3068,  3.6621,  1.7070]]])\n",
            "Shape:torch.Size([1, 8, 4])\n",
            "\n",
            "V: \n",
            "tensor([[[ 1.4962,  2.2611,  1.1062,  1.2598],\n",
            "         [ 0.1245, -0.0105,  1.1324, -1.8729],\n",
            "         [-2.1748, -1.3472, -0.3484,  2.6274],\n",
            "         [-1.6433,  0.9624, -1.7809,  1.1603],\n",
            "         [-2.1748,  1.4185, -0.3874, -2.9847],\n",
            "         [ 3.0016, -0.6142, -2.8534, -6.7328],\n",
            "         [ 1.6097,  0.9610, -1.7968,  0.3779],\n",
            "         [ 1.7644, -0.1814, -2.9607,  0.7268]]])\n",
            "Shape:torch.Size([1, 8, 4])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"K.transpose(-2, -1) changes the shape of K from [1, 8, 4] to [1, 4, 8].\\nThis is required so we can do matrix multiplication of Q and K.transpose(-2, -1)\\n\")\n",
        "print(f\"K.transpose(-2, -1): \\n{K.transpose(-2, -1)}\\nShape:{K.transpose(-2, -1).shape}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0a_yhhuZJXp",
        "outputId": "dd06bbda-bd87-4a5b-ec6d-33932930b863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K.transpose(-2, -1) changes the shape of K from [1, 8, 4] to [1, 4, 8].\n",
            "This is required so we can do matrix multiplication of Q and K.transpose(-2, -1)\n",
            "\n",
            "K.transpose(-2, -1): \n",
            "tensor([[[-0.6510, -0.9062,  0.7957, -0.0456,  1.2129,  2.1940,  1.6181,\n",
            "          -0.0881],\n",
            "         [-3.4445,  0.3995, -0.8254,  0.0406,  1.6016,  8.2014,  0.7473,\n",
            "           2.3068],\n",
            "         [-5.8930,  0.2874,  1.6934,  0.9108, -1.6721,  3.8594, -2.0546,\n",
            "           3.6621],\n",
            "         [-2.4487,  0.4378,  0.6866,  0.8759, -1.1057,  0.1499, -1.7937,\n",
            "           1.7070]]])\n",
            "Shape:torch.Size([1, 4, 8])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odBpv4Q6Pubw",
        "outputId": "d55b6a38-6a99-40a5-c394-677a9362894b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q @ K.transpose(-2, -1): \n",
            "\n",
            "tensor([[[-13.9979,   3.4052,  -1.1599,   1.9264,  -1.5992,  16.9903,  -5.3484,\n",
            "           10.2455],\n",
            "         [  6.7283,   2.0576,  -0.9522,   0.0336,  -6.1901, -18.5646,  -5.9885,\n",
            "           -3.0018],\n",
            "         [ -6.1795,  -2.2675,   3.4461,   0.8077,   2.3259,   8.7924,   2.8680,\n",
            "            2.5057],\n",
            "         [  4.9836,  -1.2118,  -2.1584,  -1.7398,   4.8392,   3.8830,   5.6394,\n",
            "           -3.5926],\n",
            "         [ 13.1541,  -1.4259,   1.3935,  -0.8083,  -3.4251, -24.9722,  -0.5913,\n",
            "           -8.7193],\n",
            "         [ 26.2861,  -5.4792,  -1.9154,  -4.6989,   7.6682, -20.1785,  13.3073,\n",
            "          -18.6718],\n",
            "         [ -5.5711,  -2.7756,   0.0558,  -0.7081,   9.1689,  22.8858,   9.1352,\n",
            "            1.9572],\n",
            "         [  5.3515,  -2.4422,  -4.7455,  -3.3527,  12.1514,  18.5630,  12.9052,\n",
            "           -4.3902]]])\n",
            "\n",
            "Shape:torch.Size([1, 8, 8])\n",
            "\n",
            "\n",
            "Note: Q @ K.transpose(-2, -1) gives a 8X8 matrix, since Q was 8X4 and K.transpose(-2, -1) was 4X8\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Compute the dot product\n",
        "scores = Q @ K.transpose(-2, -1)\n",
        "print(f\"Q @ K.transpose(-2, -1): \\n\\n{scores}\\n\\nShape:{scores.shape}\\n\\n\")\n",
        "print(\"Note: Q @ K.transpose(-2, -1) gives a 8X8 matrix, since Q was 8X4 and K.transpose(-2, -1) was 4X8\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We now need to do Casual masking (only done in the decoder model of transformers):\n",
        "- first add a new dimension to scores using torch unsqueze(0) function\n",
        "\n"
      ],
      "metadata": {
        "id": "-i1PhtOjha1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scoresU=scores.unsqueeze(0)\n",
        "print(f\"scoresU: \\n{scoresU}\\nShape:{scoresU.shape}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G6kLrrBgF2k",
        "outputId": "d5b6fa44-7539-40de-d389-6f1be9ebfdf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scoresU: \n",
            "tensor([[[[-13.9979,   3.4052,  -1.1599,   1.9264,  -1.5992,  16.9903,  -5.3484,\n",
            "            10.2455],\n",
            "          [  6.7283,   2.0576,  -0.9522,   0.0336,  -6.1901, -18.5646,  -5.9885,\n",
            "            -3.0018],\n",
            "          [ -6.1795,  -2.2675,   3.4461,   0.8077,   2.3259,   8.7924,   2.8680,\n",
            "             2.5057],\n",
            "          [  4.9836,  -1.2118,  -2.1584,  -1.7398,   4.8392,   3.8830,   5.6394,\n",
            "            -3.5926],\n",
            "          [ 13.1541,  -1.4259,   1.3935,  -0.8083,  -3.4251, -24.9722,  -0.5913,\n",
            "            -8.7193],\n",
            "          [ 26.2861,  -5.4792,  -1.9154,  -4.6989,   7.6682, -20.1785,  13.3073,\n",
            "           -18.6718],\n",
            "          [ -5.5711,  -2.7756,   0.0558,  -0.7081,   9.1689,  22.8858,   9.1352,\n",
            "             1.9572],\n",
            "          [  5.3515,  -2.4422,  -4.7455,  -3.3527,  12.1514,  18.5630,  12.9052,\n",
            "            -4.3902]]]])\n",
            "Shape:torch.Size([1, 1, 8, 8])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the size of the sequence (context length)\n",
        "context_length = scoresU.shape[-1]\n",
        "print(f\"context_length: {context_length}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWS4ADyshnDh",
        "outputId": "9406321b-5e41-43df-f7ff-699c3ec3c11e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context_length: 8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creates an upper triangular matrix with the diagonal and above filled. Setting the upper triangle to -inf ensures that softmax outputs 0 for those positions."
      ],
      "metadata": {
        "id": "eGA64588iJmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a causal mask (upper triangular part set to -inf)\n",
        "causal_mask = torch.triu(torch.full((context_length, context_length), float('-inf')), diagonal=1)\n",
        "print(f\"causal_mask: \\n{causal_mask}\\nShape:{causal_mask.shape}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqyFVLEyh7G8",
        "outputId": "11fcbcf5-865b-4b26-97fa-21309a74f68d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "causal_mask: \n",
            "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "Shape:torch.Size([8, 8])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the mask to scores\n",
        "masked_scores = scores + causal_mask\n",
        "print(f\"masked_scores: \\n{masked_scores}\\nShape:{masked_scores.shape}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-txR6zA1iZ_b",
        "outputId": "abeae5a6-fcc3-4f8a-a8e7-beccb726a0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "masked_scores: \n",
            "tensor([[[-13.9979,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,\n",
            "              -inf],\n",
            "         [  6.7283,   2.0576,     -inf,     -inf,     -inf,     -inf,     -inf,\n",
            "              -inf],\n",
            "         [ -6.1795,  -2.2675,   3.4461,     -inf,     -inf,     -inf,     -inf,\n",
            "              -inf],\n",
            "         [  4.9836,  -1.2118,  -2.1584,  -1.7398,     -inf,     -inf,     -inf,\n",
            "              -inf],\n",
            "         [ 13.1541,  -1.4259,   1.3935,  -0.8083,  -3.4251,     -inf,     -inf,\n",
            "              -inf],\n",
            "         [ 26.2861,  -5.4792,  -1.9154,  -4.6989,   7.6682, -20.1785,     -inf,\n",
            "              -inf],\n",
            "         [ -5.5711,  -2.7756,   0.0558,  -0.7081,   9.1689,  22.8858,   9.1352,\n",
            "              -inf],\n",
            "         [  5.3515,  -2.4422,  -4.7455,  -3.3527,  12.1514,  18.5630,  12.9052,\n",
            "           -4.3902]]])\n",
            "Shape:torch.Size([1, 8, 8])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fct_IafXPubx"
      },
      "source": [
        "# 2. Compute Attention Weights\n",
        "- Note that softmax makes the -inf to 0 ( this is how we acheieved the masking)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "remember we did this before:\n",
        "- import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "qJzC_19nj3Rp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4cMuzNyPubx",
        "outputId": "4105df27-e4d8-4854-e135-f69c2ab77f45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention weights:\n",
            "F.softmax(scores / (weight_dimensions ** 0.5), dim=-1): \n",
            "\n",
            "tensor([[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "         [9.1176e-01, 8.8240e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "         [7.6250e-03, 5.3916e-02, 9.3846e-01, 0.0000e+00, 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "         [9.0256e-01, 4.0755e-02, 2.5387e-02, 3.1298e-02, 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "         [9.9536e-01, 6.7919e-04, 2.7811e-03, 9.2489e-04, 2.4996e-04,\n",
            "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "         [9.9991e-01, 1.2654e-07, 7.5176e-07, 1.8692e-07, 9.0601e-05,\n",
            "          8.1338e-11, 0.0000e+00, 0.0000e+00],\n",
            "         [6.6032e-07, 2.6717e-06, 1.1006e-05, 7.5119e-06, 1.0484e-03,\n",
            "          9.9790e-01, 1.0308e-03, 0.0000e+00],\n",
            "         [1.2285e-03, 2.4946e-05, 7.8855e-06, 1.5823e-05, 3.6810e-02,\n",
            "          9.0825e-01, 5.3658e-02, 9.4187e-06]]])\n",
            "\n",
            "Shape:torch.Size([1, 8, 8])\n",
            "\n",
            "\n",
            "Note: F.softmax(scores / (weight_dimensions ** 0.5), dim=-1) gives a 8X8 matrix, since Q @ K.transpose(-2, -1) was 8X8\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Compute the attention weights with softmax (scaled by sqrt of weight dimensions)\n",
        "attention_weights = F.softmax(masked_scores / (weight_dimensions ** 0.5), dim=-1)\n",
        "print(f\"attention weights:\\nF.softmax(scores / (weight_dimensions ** 0.5), dim=-1): \\n\\n{attention_weights}\\n\\nShape:{attention_weights.shape}\\n\\n\")\n",
        "print(\"Note: F.softmax(scores / (weight_dimensions ** 0.5), dim=-1) gives a 8X8 matrix, since Q @ K.transpose(-2, -1) was 8X8\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Note:\n",
        "- **attention_weights[0][0]** accesses the attention weights for the first query position (first word in the sentence). This is a vector of size 8, where each value indicates how much attention the first word places on every word (including itself)..\n",
        "- since they were normalized, the sum would give 0"
      ],
      "metadata": {
        "id": "YxLkEJsgek3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yu3kvlWe3Ou",
        "outputId": "db512bf4-3f12-436b-ab32-4e0a236b5bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VUcF5RdPubx",
        "outputId": "584f593f-fe09-4ed0-f1da-a7378db23490"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "sum(attention_weights[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSGYPnXAPubx"
      },
      "source": [
        "# 3. Update the Meaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFwsV2vkPubx",
        "outputId": "a2bce3dd-febb-4f4a-f793-65830974fe19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.4962,  2.2611,  1.1062,  1.2598],\n",
              "         [ 1.3752,  2.0607,  1.1085,  0.9834],\n",
              "         [-2.0228, -1.2476, -0.2574,  2.3744],\n",
              "         [ 1.2489,  2.0363,  0.9800,  1.1638],\n",
              "         [ 1.4813,  2.2482,  1.0991,  1.2603],\n",
              "         [ 1.4959,  2.2611,  1.1060,  1.2594],\n",
              "         [ 2.9946, -0.6104, -2.8497, -6.7213],\n",
              "         [ 2.7343, -0.4513, -2.7010, -6.2030]]])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "context_vectors = attention_weights @ V\n",
        "context_vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explanation:**\n",
        "\n",
        "- Let's look at the first row:\n",
        "\n",
        "1.\t**Features Represent Contextualized Information:**\n",
        "- The 4 values ([1.4962, 2.2611, 1.1062, 1.2598]) represent features extracted from the self-attention mechanism.\n",
        "- These features do not directly measure the importance of the word “The” alone but instead describe its contextualized meaning based on how it interacts with other words in the sentence.\n",
        "2.\t**Contextual Importance:**\n",
        "- The values encode information about how “The” relates to other words in the sentence.\n",
        "\n",
        "\n",
        "**For example:**\n",
        "\n",
        "•\tThe representation might reflect that “The” is part of a noun phrase (“The narrator”) and is less semantically significant than a verb like “suggested.”\n",
        "\n",
        "3.\t**Features Are Learned Representations:**\n",
        "- The 4 features are learned by the model during training to be useful for the specific task (e.g., translation, summarization, or classification).\n",
        "- These features might capture linguistic properties, such as:\n",
        "- Syntactic role: Its position and relation to nearby words.\n",
        "- Semantic contribution: How much meaning it adds to the overall sentence.\n",
        "\n",
        "4.\t**Self-Attention’s Contribution:**\n",
        "•\tThe self-attention mechanism updates the representation of “The” by combining information from all other words in the sentence.\n",
        "•\tThis means the features reflect “The” in context rather than in isolation."
      ],
      "metadata": {
        "id": "miuKtweunFuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next Step:\n",
        "- Feed Context Vectors into a Feedforward Neural Network"
      ],
      "metadata": {
        "id": "VtBMk35NpKvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the feedforward network\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)  # First dense layer\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)  # Second dense layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))  # Apply ReLU activation after first layer\n",
        "        x = self.fc2(x)          # Second layer (no activation in this example)\n",
        "        return x\n",
        "\n",
        "# Initialize the feedforward network\n",
        "input_dim = 4  # Same as the dimension of context vectors\n",
        "hidden_dim = 8  # Example hidden dimension\n",
        "output_dim = 4  # Output dimension (same as input in this case)\n",
        "feedforward = FeedForward(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "# Apply the feedforward network\n",
        "output_vectors = feedforward(context_vectors)\n",
        "\n",
        "# Print the results\n",
        "print(\"Input Context Vectors:\")\n",
        "print(context_vectors)\n",
        "print(\"\\nOutput Vectors After Feedforward Network:\")\n",
        "print(output_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM9LIqP_qEVe",
        "outputId": "17a57168-85c7-495f-8fd9-25e5ecc8e40c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Context Vectors:\n",
            "tensor([[[ 1.4962,  2.2611,  1.1062,  1.2598],\n",
            "         [ 1.3752,  2.0607,  1.1085,  0.9834],\n",
            "         [-2.0228, -1.2476, -0.2574,  2.3744],\n",
            "         [ 1.2489,  2.0363,  0.9800,  1.1638],\n",
            "         [ 1.4813,  2.2482,  1.0991,  1.2603],\n",
            "         [ 1.4959,  2.2611,  1.1060,  1.2594],\n",
            "         [ 2.9946, -0.6104, -2.8497, -6.7213],\n",
            "         [ 2.7343, -0.4513, -2.7010, -6.2030]]])\n",
            "\n",
            "Output Vectors After Feedforward Network:\n",
            "tensor([[[-0.0686, -0.2526, -0.2422, -0.3847],\n",
            "         [-0.0456, -0.1881, -0.2578, -0.3903],\n",
            "         [-0.2518,  0.1164,  0.0683, -0.1425],\n",
            "         [-0.0733, -0.2142, -0.2418, -0.3633],\n",
            "         [-0.0690, -0.2512, -0.2418, -0.3834],\n",
            "         [-0.0686, -0.2525, -0.2423, -0.3847],\n",
            "         [ 0.9509, -0.1000,  0.1879,  0.3600],\n",
            "         [ 0.8633, -0.0643,  0.1646,  0.3132]]], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add Residual Connections for stability"
      ],
      "metadata": {
        "id": "tU7aJ7Zrq087"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_vectors += context_vectors\n",
        "output_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ0k2Fohq75h",
        "outputId": "1a836b63-c288-462c-dcb0-ca6cbd40bf2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.4277,  2.0086,  0.8640,  0.8751],\n",
              "         [ 1.3296,  1.8726,  0.8507,  0.5931],\n",
              "         [-2.2747, -1.1312, -0.1891,  2.2318],\n",
              "         [ 1.1756,  1.8222,  0.7382,  0.8004],\n",
              "         [ 1.4123,  1.9969,  0.8573,  0.8770],\n",
              "         [ 1.4273,  2.0086,  0.8638,  0.8747],\n",
              "         [ 3.9456, -0.7104, -2.6618, -6.3613],\n",
              "         [ 3.5976, -0.5155, -2.5363, -5.8899]]], grad_fn=<AsStridedBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalize to stabilize and scale the results\n",
        "- each row will have mean of 0 with standard deviation of 1"
      ],
      "metadata": {
        "id": "-asVkVGYrI5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm = nn.LayerNorm(output_vectors.size()[-1])\n",
        "normalized_output = norm(output_vectors)\n",
        "normalized_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzdYFpZWrPPw",
        "outputId": "dddfdbe4-8dd3-49d4-892c-4da1797124da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.2839,  1.5162, -0.9118, -0.8883],\n",
              "         [ 0.3442,  1.4564, -0.6365, -1.1642],\n",
              "         [-1.1659, -0.4765,  0.0914,  1.5509],\n",
              "         [ 0.0962,  1.5962, -0.9184, -0.7740],\n",
              "         [ 0.2706,  1.5225, -0.9176, -0.8755],\n",
              "         [ 0.2836,  1.5163, -0.9115, -0.8884],\n",
              "         [ 1.4510,  0.1982, -0.3269, -1.3223],\n",
              "         [ 1.4364,  0.2389, -0.3494, -1.3258]]],\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notes on using pre-trained model for Embeddings\n",
        "- often used for RAG workflow"
      ],
      "metadata": {
        "id": "SW0E5gz8EBrQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder-Only Models:\n",
        "- Models like **all-MiniLM-L6-v2** consist of stacked **encoder layers**.\n",
        "- Each encoder layer includes:\n",
        "  - Multi-headed self-attention\n",
        "  - Feedforward neural networks\n",
        "  - Residual connections\n",
        "\n",
        "## Decoder-Only Models (e.g., OpenAI GPT):\n",
        "- Decoder-only models like GPT can generate embeddings.\n",
        "- For embedding tasks:\n",
        "  - They disable causal masking and use the **final hidden states** from the decoder as embeddings.\n"
      ],
      "metadata": {
        "id": "3UEOuoGPEKkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Note on Casual Masking"
      ],
      "metadata": {
        "id": "YftVIAogG2dv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Causal Masking in Transformer Architectures**\n",
        "- Causal Masking is applied **only in the decoder block** of a Transformer model.\n",
        "- Its purpose is to **ensure that the model cannot “see” future tokens** when predicting the next word during autoregressive generation.\n",
        "\n",
        "**Why It’s Needed in Decoders:**\n",
        "- In tasks like text generation (e.g., GPT models), the decoder predicts one token at a time in sequence:\n",
        "- When predicting the  i -th token, the model must only attend to previous tokens (tokens 1 to  i-1 ).\n",
        "- Causal masking ensures that the decoder does not attend to future tokens during training.\n",
        "\n",
        "2. **Encoder Blocks Do Not Use Causal Masking**\n",
        "- In the encoder block of a Transformer:\n",
        "\t- The self-attention mechanism operates over the entire input sequence.\n",
        "\t- Tokens are allowed to attend to all other tokens (both before and after) in the input sentence.\n",
        "\n",
        "**Why?**\n",
        "\n",
        "- The encoder’s goal is to create a contextualized representation of the input tokens by considering relationships between all tokens in the input simultaneously.\n",
        "- There’s no need to restrict attention to past tokens, as the task doesn’t involve sequential generation."
      ],
      "metadata": {
        "id": "qFM-Bv6TG5MS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multi-Headed Self-Attention**\n",
        "\n",
        "In **multi-headed self-attention**, multiple attention heads run independently to capture different types of relationships:\n",
        "\n",
        "1. **Independent Attention Heads**:\n",
        "   - Each head has its own \\( W_Q, W_K, W_V \\), producing unique Q, K, V matrices.\n",
        "2. **Combine Outputs**:\n",
        "   - Outputs from all heads are concatenated and passed through a final linear transformation."
      ],
      "metadata": {
        "id": "vZ2mKLmFKnSP"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}