{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyPUOz17+QOleQ7BknpbcUrc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"bd4b2ff050f440058f5a5e9a136af570":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4376732328af48a5b3a4e964c867475b","IPY_MODEL_62912360aecd4fe5b5b08fa52dc9fac9","IPY_MODEL_de74a87c87c3416bb3b706e1462f0a0b"],"layout":"IPY_MODEL_8fb8b610f51d4e43850f245a626da803"}},"4376732328af48a5b3a4e964c867475b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54431787159947a49ebcc7e68d96ab00","placeholder":"​","style":"IPY_MODEL_21d035cfcbd2451f84558288fc79f503","value":"Loading checkpoint shards: 100%"}},"62912360aecd4fe5b5b08fa52dc9fac9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4709e926d69c4900bce90f20b2c4e088","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_87edf225ddde4e65b8f6617d21604db0","value":2}},"de74a87c87c3416bb3b706e1462f0a0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f360cb8f1094111945888893e5e10a7","placeholder":"​","style":"IPY_MODEL_6ba96cdf807444aaa4051b6157195a8a","value":" 2/2 [00:01&lt;00:00,  1.70it/s]"}},"8fb8b610f51d4e43850f245a626da803":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54431787159947a49ebcc7e68d96ab00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21d035cfcbd2451f84558288fc79f503":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4709e926d69c4900bce90f20b2c4e088":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87edf225ddde4e65b8f6617d21604db0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3f360cb8f1094111945888893e5e10a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ba96cdf807444aaa4051b6157195a8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# mount drive and configure envs"],"metadata":{"id":"S-0ppDBfRr18"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P_7icbpAhggn","executionInfo":{"status":"ok","timestamp":1741413029935,"user_tz":360,"elapsed":407,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}},"outputId":"be5b9a65-77f6-4394-fbab-dc8666748f69"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/GL-GenAI/Week13-AdvancedGenAI/langgraphTutorials')\n","os.listdir()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RbPJQoMChlNr","executionInfo":{"status":"ok","timestamp":1741413031361,"user_tz":360,"elapsed":9,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}},"outputId":"6b300bfe-1b94-43e6-9aeb-2402375ef8a4"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['.env', 'langGraphAgent.ipynb', 'RAG_LangGraph.ipynb', 'my_chroma_db']"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["# %%writefile .env\n","# OPENAI_API_KEY=\"\"\n","# LANGSMITH_API_KEY=\"\"\n","# LANGSMITH_TRACING=true\n","# AGENT_API_KEY=\"\"\n"],"metadata":{"id":"xh8Sbgywhn5i","executionInfo":{"status":"ok","timestamp":1741413034162,"user_tz":360,"elapsed":10,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["pip install -q python-dotenv"],"metadata":{"id":"AynS9XXVhqoh","executionInfo":{"status":"ok","timestamp":1741413039302,"user_tz":360,"elapsed":2610,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import openai\n","from dotenv import load_dotenv"],"metadata":{"id":"zbp6z6KjhtUk","executionInfo":{"status":"ok","timestamp":1741413043245,"user_tz":360,"elapsed":686,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Set environment variable to avoid tokenizer warnings\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n","\n","# Force reload of environment variables\n","load_dotenv(override=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vcyUWoTRhweI","executionInfo":{"status":"ok","timestamp":1741413045097,"user_tz":360,"elapsed":9,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}},"outputId":"b7d41316-ccb7-40f5-a808-06edc3e81199"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Set the OpenAI API key from the environment variable\n","openai.api_key = os.getenv('OPENAI_API_KEY')\n","LANGSMITH_API_KEY = os.getenv('LANGSMITH_API_KEY')\n","LANGSMITH_TRACING = os.getenv('LANGSMITH_TRACING')\n","AGENT_API_KEY = os.getenv('AGENT_API_KEY')\n","\n","# print(openai.api_key)   # only for testing\n","# print(LANGSMITH_API_KEY)\n","# print(LANGSMITH_TRACING)\n","# print(AGENT_API_KEY)"],"metadata":{"id":"GaQMn6tShzNO","executionInfo":{"status":"ok","timestamp":1741413048395,"user_tz":360,"elapsed":3,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M4uw0tzf2u7s","executionInfo":{"status":"ok","timestamp":1741413051268,"user_tz":360,"elapsed":111,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}},"outputId":"1a1d3302-67b6-40e8-d250-687685130f7b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Mar  8 05:50:51 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   55C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["# References:"],"metadata":{"id":"inA3L61Ch27P"}},{"cell_type":"markdown","source":["- https://www.youtube.com/watch?v=uAEbMpzI3Eg"],"metadata":{"id":"bL8HJnOrh3__"}},{"cell_type":"markdown","source":["# Start Coding"],"metadata":{"id":"lmGjPhIIiEBf"}},{"cell_type":"code","source":["!pip install -q langchain langchain-core langchain_community langgraph langchain-huggingface transformers torch"],"metadata":{"id":"OKNcq-AmiDUe","executionInfo":{"status":"ok","timestamp":1741413057741,"user_tz":360,"elapsed":3010,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Data Loaders\n","- https://python.langchain.com/docs/integrations/document_loaders/"],"metadata":{"id":"qg1Uzo3ViY7A"}},{"cell_type":"code","source":["!pip install -q unstructured\n","\n","from langchain_community.document_loaders import UnstructuredURLLoader\n","\n","urls = ['https://langchain-ai.github.io/langgraph/tutorials/introduction/']\n","loader = UnstructuredURLLoader(urls=urls)\n","docs = loader.load()"],"metadata":{"id":"1mwAz3wBjBsW","executionInfo":{"status":"ok","timestamp":1741413070938,"user_tz":360,"elapsed":9048,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## chunking\n","- using chunk_size of 1000\n","- using overlap of 200"],"metadata":{"id":"Xd-T4YnljG_a"}},{"cell_type":"markdown","source":["- I noticed that you are using HuggingFaceEmbeddings, which I believe defaults to: all-MiniLM-L6-v2\n","-  since all-MiniLM-L6-v2 has embedding dimensions of 384, would not doing chunking with 1000 cause a problem ?  A chunk size of 1000 tokens would exceed the maximum input size for most HuggingFace embedding models, potentially causing errors or truncation of input ?"],"metadata":{"id":"smcUdH2-o05d"}},{"cell_type":"code","source":["\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200) # (chunk_size=1000, chunk_overlap=200)\n","all_splits = text_splitter.split_documents(docs)\n","\n","print(\"Total number of documents: \",len(all_splits))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OgKILKhhjMbE","executionInfo":{"status":"ok","timestamp":1741413075431,"user_tz":360,"elapsed":41,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}},"outputId":"a5f0976b-6408-45be-84ca-db2c9ff15c48"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of documents:  98\n"]}]},{"cell_type":"code","source":["all_splits[7]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bQSBwx2RjpLl","executionInfo":{"status":"ok","timestamp":1741413079029,"user_tz":360,"elapsed":10,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}},"outputId":"ec17c856-fb47-43da-8b3a-67a440b463cf"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/introduction/'}, page_content=\"Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It's particularly useful for developing more complex, stateful AI applications that go beyond simple query-response interactions.\\nGoodbye!\\n\\nCongratulations! You've built your first chatbot using LangGraph. This bot can engage in basic conversation by taking user input and generating responses using an LLM. You can inspect a LangSmith Trace for the call above at the provided link.\\n\\nHowever, you may have noticed that the bot's knowledge is limited to what's in its training data. In the next part, we'll add a web search tool to expand the bot's knowledge and make it more capable.\")"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["## Embedding\n","- Embedding models: https://python.langchain.com/v0.1/docs/integrations/text_embedding/"],"metadata":{"id":"Xbj91meljuTB"}},{"cell_type":"code","source":["!pip install -q  langchain_huggingface"],"metadata":{"id":"7sz-R6x0pdKS","executionInfo":{"status":"ok","timestamp":1741413085534,"user_tz":360,"elapsed":2814,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["from sentence_transformers import SentenceTransformer"],"metadata":{"id":"2BpaYtGLSyS-","executionInfo":{"status":"ok","timestamp":1741413097298,"user_tz":360,"elapsed":9074,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["from langchain_huggingface import HuggingFaceEmbeddings"],"metadata":{"id":"jC9H4Nt7ppch","executionInfo":{"status":"ok","timestamp":1741413099753,"user_tz":360,"elapsed":416,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["embedding_model_name = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\""],"metadata":{"id":"uYsK2eBc6WZx","executionInfo":{"status":"ok","timestamp":1741413101527,"user_tz":360,"elapsed":3,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["import rich"],"metadata":{"id":"03zggQ6I7Hx8","executionInfo":{"status":"ok","timestamp":1741413106669,"user_tz":360,"elapsed":41,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Initialize SentenceTransformer\n","embedding_model = SentenceTransformer(embedding_model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CIoz4Hdm6_9h","executionInfo":{"status":"ok","timestamp":1741413112728,"user_tz":360,"elapsed":2437,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}},"outputId":"1a2153ec-460c-4d98-c5d0-29422eef7d4c"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["embedding_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T39ZfYhp8Jj-","executionInfo":{"status":"ok","timestamp":1741413114896,"user_tz":360,"elapsed":5,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}},"outputId":"78748678-9388-4b16-ef20-7185e23d7c8e"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SentenceTransformer(\n","  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: MPNetModel \n","  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",")"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# Initialize HuggingFaceEmbeddings with explicit model name\n","embeddings = HuggingFaceEmbeddings(\n","    model_name=embedding_model_name,  # Use the string name, not the model instance\n","    model_kwargs={'device': 'cpu'},\n","    encode_kwargs={'normalize_embeddings': True}\n",")\n"],"metadata":{"id":"U86IsLNhqrNU","executionInfo":{"status":"ok","timestamp":1741413120800,"user_tz":360,"elapsed":875,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["vector = embeddings.embed_query(\"this is a joke\")\n","vector[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e6AHyEeVq2M9","executionInfo":{"status":"ok","timestamp":1741413124743,"user_tz":360,"elapsed":49,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}},"outputId":"d7be822e-d75e-4848-e4a1-f72da5170dfb"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.029852118343114853,\n"," -0.05719646066427231,\n"," -0.0989520475268364,\n"," -0.01926577277481556,\n"," 0.006274454295635223]"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["## Vectorstore: Chroma"],"metadata":{"id":"9vbJQvnpj8tB"}},{"cell_type":"code","source":["!pip install -q langchain_chroma"],"metadata":{"id":"kS0XIjfNvLzv","executionInfo":{"status":"ok","timestamp":1741413131841,"user_tz":360,"elapsed":3017,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["from langchain_chroma import Chroma # import the Chroma class.\n","from langchain_core.documents import Document"],"metadata":{"id":"V0q-VyZFN9O0","executionInfo":{"status":"ok","timestamp":1741413134757,"user_tz":360,"elapsed":401,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# import shutil\n","# import os\n","# # Delete the old vectorstore\n","# if os.path.exists(\"./my_chroma_db\"):\n","#     shutil.rmtree(\"./my_chroma_db\")\n","\n","\n","# from langchain_chroma import Chroma\n","# from langchain_core.documents import Document\n","\n","# Recreate the vectorstore with the current embedding model\n","vectorstore = Chroma.from_documents(\n","    documents=all_splits,\n","    embedding=embeddings,\n","    persist_directory=\"./my_chroma_db\"\n",")"],"metadata":{"id":"OK7GdD7f9pmj","executionInfo":{"status":"ok","timestamp":1741413196857,"user_tz":360,"elapsed":59171,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["### Loading the vector store"],"metadata":{"id":"sZYnqkU5kUqy"}},{"cell_type":"code","source":["# Loading the Database Later\n","# This reloads the previously stored embeddings so you don’t have to recompute them.\n","\n","vectorstore = Chroma(\n","    persist_directory=\"./my_chroma_db\",\n","    embedding_function=embeddings\n",")\n",""],"metadata":{"id":"5Ix2pXRekYH3","executionInfo":{"status":"ok","timestamp":1741413201140,"user_tz":360,"elapsed":17,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["## Setting up Hugging Face Pipeline for model"],"metadata":{"id":"S1r7md4mxnpV"}},{"cell_type":"markdown","source":["- This code sets up a Falcon-7B language model for text generation using Hugging Face Transformers. It creates a text generation pipeline and wraps it inside HuggingFacePipeline to be used as an LLM.\n","\n","- device=0, # Runs the model on GPU (CUDA device 0) for acceleration.\n","\n","\n"],"metadata":{"id":"6s9SQnM9xr9w"}},{"cell_type":"code","source":["from langchain_huggingface import HuggingFacePipeline\n","from langchain.prompts import PromptTemplate\n","from transformers import pipeline\n","from langchain_core.output_parsers import StrOutputParser\n","import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","\n","#model_id = \"meta-llama/Meta-Llama-3-8B\"\n","model_id = \"tiiuae/falcon-7b\"\n","\n","# text_generation_pipeline = pipeline(\n","#     \"text-generation\", model=model_id, model_kwargs={\"torch_dtype\": torch.bfloat16}, max_new_tokens=400, device=0)\n","\n","\n","text_generation_pipeline = pipeline(\n","    \"text-generation\",\n","    model=model_id,\n","    model_kwargs={\"torch_dtype\": torch.bfloat16},\n","    max_new_tokens=400,\n","    device=0, # Runs the model on GPU (CUDA device 0) for acceleration.\n","    temperature=0.7,  #  (lower values = more deterministic)\n","    top_k=50,  # Filters out low-probability tokens\n",")\n","\n","\n","llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["bd4b2ff050f440058f5a5e9a136af570","4376732328af48a5b3a4e964c867475b","62912360aecd4fe5b5b08fa52dc9fac9","de74a87c87c3416bb3b706e1462f0a0b","8fb8b610f51d4e43850f245a626da803","54431787159947a49ebcc7e68d96ab00","21d035cfcbd2451f84558288fc79f503","4709e926d69c4900bce90f20b2c4e088","87edf225ddde4e65b8f6617d21604db0","3f360cb8f1094111945888893e5e10a7","6ba96cdf807444aaa4051b6157195a8a"]},"id":"9t-gPYkmw0Ib","executionInfo":{"status":"ok","timestamp":1741413212193,"user_tz":360,"elapsed":5901,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}},"outputId":"6f866730-25f9-4db2-a518-69832a20ec35"},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd4b2ff050f440058f5a5e9a136af570"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]}]},{"cell_type":"markdown","source":["## cleaning up memory if trying to load again with different parameters"],"metadata":{"id":"MABYcl66RjWd"}},{"cell_type":"code","source":["# import torch\n","\n","# # Empty CUDA cache to free up memory\n","# torch.cuda.empty_cache()\n","\n","# # Force garbage collection to remove unused objects\n","# import gc\n","# gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tp--ikC1RiqM","executionInfo":{"status":"ok","timestamp":1741412565403,"user_tz":360,"elapsed":46,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}},"outputId":"c4e21548-3524-44db-ec24-44be6c7828f0"},"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5711"]},"metadata":{},"execution_count":57}]},{"cell_type":"markdown","source":["## Define Prompt"],"metadata":{"id":"utp95Y0HyGBS"}},{"cell_type":"code","source":["# from langchain_core.prompts import PromptTemplate\n","\n","# template = \"\"\"Use the following pieces of context to answer the question at the end.\n","# If you don't know the answer, just say that you don't know, don't try to make up an answer.\n","# Use three sentences maximum and keep the answer as concise as possible.\n","# Always say \"thanks for asking!\" at the end of the answer.\n","\n","# {context}\n","\n","# Question: {question}\n","\n","# Helpful Answer:\"\"\"\n","# prompt = PromptTemplate.from_template(template)\n","\n","\n","from langchain import hub\n","\n","prompt = hub.pull(\"rlm/rag-prompt\")"],"metadata":{"id":"hgaAOPX4yAra","executionInfo":{"status":"ok","timestamp":1741413231213,"user_tz":360,"elapsed":483,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["print(prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qZbKQ7dxyT-A","executionInfo":{"status":"ok","timestamp":1741413237695,"user_tz":360,"elapsed":5,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}},"outputId":"fee16360-291d-4eae-e7a8-64a014a4c86d"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n"]}]},{"cell_type":"code","source":["# Extract the prompt template from the ChatPromptTemplate object\n","print(prompt.messages[0].prompt.template)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0kJ0hyWmy5xl","executionInfo":{"status":"ok","timestamp":1741413239961,"user_tz":360,"elapsed":4,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}},"outputId":"43413c8b-42a4-49db-b291-e81c723ca8cd"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n","Question: {question} \n","Context: {context} \n","Answer:\n"]}]},{"cell_type":"markdown","source":["## defining the state"],"metadata":{"id":"Ggfrq-u1z6UY"}},{"cell_type":"markdown","source":["- \tTypedDict → Allows defining structured dictionaries with explicit types for each key.\n","- List → Used to specify that context is a list of Document objects\n","\n","**State is a dictionary-like structure that explicitly defines:**\n","- question: The user’s query (string).\n","- context: A list of retrieved documents (likely from a database or vector store).\n","- answer: The generated response from the model."],"metadata":{"id":"4xOgEbwTPFgW"}},{"cell_type":"code","source":["\n","#from typing_extensions import List, TypedDict\n","from typing import List, TypedDict\n","\n","# Define state for application\n","class State(TypedDict):\n","    question: str\n","    context: List[Document]\n","    answer: str\n"],"metadata":{"id":"clykveWHzxFP","executionInfo":{"status":"ok","timestamp":1741413245849,"user_tz":360,"elapsed":2,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["# Define application state (the nodes)"],"metadata":{"id":"8yrOPhJA0B2b"}},{"cell_type":"code","source":["# Define application steps\n","def retrieve(state: State):\n","    retrieved_docs = vectorstore.similarity_search(state[\"question\"],  k=1)\n","    return {\"context\": retrieved_docs}"],"metadata":{"id":"K_ttUaeV0AQ3","executionInfo":{"status":"ok","timestamp":1741413252359,"user_tz":360,"elapsed":6,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["def generate(state: State):\n","    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n","    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n","    response = llm.invoke(messages)\n","    #return {\"answer\": response.content}\n","    return {\"answer\": response}"],"metadata":{"id":"aTRich7z0LXB","executionInfo":{"status":"ok","timestamp":1741413254565,"user_tz":360,"elapsed":2,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["## Define the langGraph"],"metadata":{"id":"3Pj_1s8N0V4l"}},{"cell_type":"code","source":["from langgraph.graph import START, StateGraph\n","\n","# Compile application and test\n","graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n","graph_builder.add_edge(START, \"retrieve\")\n","graph = graph_builder.compile()"],"metadata":{"id":"JOiAUnGJ0YEl","executionInfo":{"status":"ok","timestamp":1741413263348,"user_tz":360,"elapsed":57,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["from IPython.display import Image, display\n","\n","display(Image(graph.get_graph().draw_mermaid_png()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":251},"id":"tdaaMj9v0wlo","executionInfo":{"status":"ok","timestamp":1741413265900,"user_tz":360,"elapsed":103,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}},"outputId":"517db648-276b-4060-9e91-e66c8b06debb"},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}}]},{"cell_type":"code","source":["response = graph.invoke({\"question\": \"what is langgraph?\"})\n","print(response[\"answer\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ws0o3i4J05Xr","executionInfo":{"status":"ok","timestamp":1741413311359,"user_tz":360,"elapsed":36010,"user":{"displayName":"Soumitra Mukherji","userId":"02267047127611459680"}},"outputId":"06b721f9-87a8-481e-fb3c-0f9420c928bd"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Human: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n","Question: what is langgraph? \n","Context: Thank you for your patience. I've found some recent information about LangGraph for you. Let me summarize the key points:\n","\n","1. LangGraph is part of the LangChain ecosystem, which is a leading platform in AI development.\n","\n","2. Recent updates and features of LangGraph include:\n","\n","   a. LangGraph Cloud: This seems to be a cloud-based version of LangGraph, though specific details weren't provided in the search results.\n","\n","   b. LangGraph Platform: This is a newly introduced concept that combines several offerings:\n","      - LangGraph Server\n","      - LangGraph Studio\n","      - CLI (Command Line Interface)\n","      - SDK (Software Development Kit)\n","\n","3. LangGraph Server: This component has received new features to enhance its value proposition, though the specific features weren't detailed in the search results.\n","\n","4. LangGraph Studio: This appears to be a new tool in the LangGraph ecosystem, likely providing a graphical interface for working with LangGraph. \n","Answer: LangGraph is a cloud-based platform for AI development. It includes a server, a studio, and a CLI. LangGraph Studio is a new tool in the LangGraph ecosystem.\n","\n","Thank you for your patience. I've found some recent information about LangGraph for you. Let me summarize the key points:\n","\n","1. LangGraph is part of the LangChain ecosystem, which is a leading platform in AI development.\n","\n","2. Recent updates and features of LangGraph include:\n","\n","a. LangGraph Cloud: This seems to be a cloud-based version of LangGraph, though specific details weren't provided in the search results.\n","\n","b. LangGraph Platform: This is a newly introduced concept that combines several offerings:\n","\n","c. LangGraph Server: This component has received new features to enhance its value proposition, though the specific features weren't detailed in the search results.\n","\n","d. LangGraph Studio: This appears to be a new tool in the LangGraph ecosystem, likely providing a graphical interface for working with LangGraph.\n","\n","Answer: LangGraph is a cloud-based platform for AI development. It includes a server, a studio, and a CLI. LangGraph Studio is a new tool in the LangGraph ecosystem.\n","\n","Thank you for your patience. I've found some recent information about LangGraph for you. Let me summarize the key points:\n","\n","1. LangGraph is part of the LangChain ecosystem, which is a leading platform in AI development.\n","\n","2. Recent updates and features of LangGraph include:\n","\n","a. LangGraph Cloud: This seems to be a cloud-based version of LangGraph, though specific details weren't provided in the search results.\n","\n","b. LangGraph Platform: This is a newly introduced concept that combines several offerings:\n","\n","c. LangGraph Server: This component has received new features to enhance its value proposition, though the specific features weren\n"]}]}]}